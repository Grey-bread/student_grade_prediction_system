"""
æ¨¡å‹è®­ç»ƒè·¯ç”±

èŒè´£ï¼š
- æä¾›åŸºäºæ•°æ®åº“çœŸå®æ•°æ®çš„è®­ç»ƒæ¥å£ï¼ˆPOST /trainï¼‰
- æä¾›å·²ä¿å­˜æ¨¡å‹åˆ—è¡¨ï¼ˆGET /modelsï¼‰
- æä¾›è®­ç»ƒæ•°æ®ç»Ÿè®¡ï¼ˆGET /data-statsï¼‰

æ³¨æ„ï¼š
- å½“å‰ç¤ºä¾‹ä»…è¿”å›è¯„ä¼°ç»“æœä¸å¯è§†åŒ–ï¼Œä¸å®é™…æŒä¹…åŒ–æ¨¡å‹ï¼ˆå¯æŒ‰éœ€å¼€å¯ï¼‰
"""

# -*- coding: utf-8 -*-
from flask import Blueprint, request, jsonify
from database import fetch_all, execute_query
from services.prediction import PredictionService
import pandas as pd
import traceback
import sys
import pickle
import os
from datetime import datetime

training_bp = Blueprint('training_bp', __name__)

# æ¨¡å‹ä¿å­˜ç›®å½•
MODEL_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'models')
os.makedirs(MODEL_DIR, exist_ok=True)

@training_bp.route('/train', methods=['POST'])
def train_model():
    """
    è®­ç»ƒæˆç»©é¢„æµ‹æ¨¡å‹ï¼ˆæ”¯æŒä»æ•°æ®åº“åŠ è½½æ•°æ®ï¼‰ã€‚
    å…¥å‚ JSONï¼š
    - targetColumn: ç›®æ ‡åˆ—ï¼ˆé»˜è®¤ total_scoreï¼‰
    - testSize: æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆ0-1ï¼Œé»˜è®¤ 0.2ï¼‰
    - dataSource: æ•°æ®æºï¼ˆå½“å‰æ”¯æŒ databaseï¼‰
    """
    try:
        data = request.get_json(force=True)
        target_column = data.get('targetColumn', 'total_score')
        test_size = float(data.get('testSize', 0.2))
        data_source = data.get('dataSource', 'database')  # database æˆ– upload
        
        print(f"ğŸ“Š å¼€å§‹è®­ç»ƒæ¨¡å‹ - ç›®æ ‡åˆ—: {target_column}, æµ‹è¯•é›†æ¯”ä¾‹: {test_size}")
        
        # ä»æ•°æ®åº“åŠ è½½è®­ç»ƒæ•°æ®
        if data_source == 'database':
            # æŸ¥è¯¢å†å²æˆç»©æ•°æ®ï¼Œè”åˆå­¦ç”Ÿä¿¡æ¯
            query = """
                SELECT 
                    s.student_id,
                    s.gender,
                    s.grade,
                    s.class,
                    hg.course_id,
                    hg.semester,
                    hg.academic_year,
                    hg.midterm_score,
                    hg.final_score,
                    hg.usual_score,
                    hg.total_score,
                    hg.grade_level,
                    hg.ranking
                FROM historical_grades hg
                JOIN students s ON hg.student_id = s.student_id
                WHERE hg.total_score IS NOT NULL
                LIMIT 5000
            """
            
            print("ğŸ” ä»æ•°æ®åº“æŸ¥è¯¢è®­ç»ƒæ•°æ®...")
            rows = fetch_all(query)
            
            if not rows or len(rows) == 0:
                return jsonify({
                    'status': 'error',
                    'message': 'æ•°æ®åº“ä¸­æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®'
                }), 400
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(rows)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®­ç»ƒæ•°æ®")
            print(f"ğŸ“‹ æ•°æ®åˆ—: {df.columns.tolist()}")
            
        else:
            return jsonify({
                'status': 'error',
                'message': 'æš‚ä¸æ”¯æŒä¸Šä¼ æ–‡ä»¶è®­ç»ƒ'
            }), 400
        
        # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
        if target_column not in df.columns:
            available_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
            return jsonify({
                'status': 'error',
                'message': f'ç›®æ ‡åˆ— {target_column} ä¸å­˜åœ¨ï¼Œå¯ç”¨çš„æ•°å€¼åˆ—: {available_cols}'
            }), 400
        
        # ä½¿ç”¨é¢„æµ‹æœåŠ¡è¿›è¡Œè®­ç»ƒ
        prediction_service = PredictionService()
        
        print("ğŸ¤– å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        result = prediction_service.train_predict(df, target_col=target_column, test_size=test_size)
        
    # ä¿å­˜æ¨¡å‹ï¼ˆç¤ºä¾‹å…³é—­ï¼Œå¦‚éœ€ä¿å­˜è¯·å–æ¶ˆæ³¨é‡Šï¼‰
        model_filename = f"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        model_path = os.path.join(MODEL_DIR, model_filename)
        
    # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…éœ€è¦ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        # with open(model_path, 'wb') as f:
        #     pickle.dump(result['best_model'], f)
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"ğŸ“Š RÂ² åˆ†æ•°: {result['metrics']['r2']:.4f}")
        print(f"ğŸ“Š MAE: {result['metrics']['mae']:.4f}")
        print(f"ğŸ“Š RMSE: {result['metrics']['rmse']:.4f}")
        
        # è¿”å›è®­ç»ƒç»“æœ
        return jsonify({
            'status': 'success',
            'message': 'æ¨¡å‹è®­ç»ƒå®Œæˆ',
            'data': {
                'metrics': result['metrics'],
                'model_results': result['model_results'],
                'best_params': result['best_params'],
                'feature_importance': result['feature_importance'][:10] if result['feature_importance'] else [],
                'visualizations': result['visualizations'],
                'model_file': model_filename,
                'training_samples': len(df),
                'target_column': target_column
            }
        }), 200
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
        traceback.print_exc(file=sys.stdout)
        return jsonify({
            'status': 'error',
            'message': f'è®­ç»ƒå¤±è´¥: {str(e)}'
        }), 500


@training_bp.route('/models', methods=['GET'])
def get_models():
    """
    è·å–å·²è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
    """
    try:
        models = []
        if os.path.exists(MODEL_DIR):
            for filename in os.listdir(MODEL_DIR):
                if filename.endswith('.pkl'):
                    filepath = os.path.join(MODEL_DIR, filename)
                    stat = os.stat(filepath)
                    models.append({
                        'filename': filename,
                        'size': stat.st_size,
                        'created_at': datetime.fromtimestamp(stat.st_ctime).strftime('%Y-%m-%d %H:%M:%S')
                    })
        
        return jsonify({
            'status': 'success',
            'data': models
        }), 200
        
    except Exception as e:
        traceback.print_exc(file=sys.stdout)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@training_bp.route('/data-stats', methods=['GET'])
def get_training_data_stats():
    """
    è·å–è®­ç»ƒæ•°æ®ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # ç»Ÿè®¡å¯ç”¨çš„è®­ç»ƒæ•°æ®é‡
        stats_query = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT student_id) as total_students,
                COUNT(DISTINCT course_id) as total_courses,
                AVG(total_score) as avg_score,
                MIN(total_score) as min_score,
                MAX(total_score) as max_score
            FROM historical_grades
            WHERE total_score IS NOT NULL
        """
        
        stats = fetch_all(stats_query)
        
        # æŒ‰å­¦æœŸç»Ÿè®¡
        semester_stats_query = """
            SELECT 
                semester,
                academic_year,
                COUNT(*) as record_count,
                AVG(total_score) as avg_score
            FROM historical_grades
            WHERE total_score IS NOT NULL
            GROUP BY semester, academic_year
            ORDER BY academic_year DESC, semester
            LIMIT 10
        """
        
        semester_stats = fetch_all(semester_stats_query)
        
        return jsonify({
            'status': 'success',
            'data': {
                'overall': stats[0] if stats else {},
                'by_semester': semester_stats
            }
        }), 200
        
    except Exception as e:
        traceback.print_exc(file=sys.stdout)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500
